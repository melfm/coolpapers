# Faster R-CNN
- region proposal algorithms: hypothesize object locations
- introduces a Region Proposal Network (RPN) that shares full-image convolutional features with the
detection network, enabling nearly cost-free region proposals.
- An RPN is a fully convolutional network that simultaneously predicts object bounds and objectness scores
at each position.
- RPN is trained end-to-end to generate high-quality region proposals
- 'attention' mechanism, the RPN components tells the unified network where to look.

## Related work
### Region proposal
- Rely on inexpensive feature and economical inference schemes
- Selective search one of the most popular methods, greedily merges
superpixels based on engineered low-level features.
- EdgeBoxes provide the best tradeoff between proposal quality and speed
- Region proposal networks share convolutional layers

### Shared computation of convolutions
- The OverFeat paper computes convolutional features from an image pyramid for classification, localization
and detection.
- Adaptively-sized pooling (SPP) on shared convolutional feature maps is developed for efficient region-based
object detection and semantic segmentation.

## Architecture
- Faster R-CNN composed of two modules
- First is a deep fully convolutional network that proposes regions and the second module is the Fast R-CNN detector
that uses the proposed regions.
- The entire system is a single, unified network for object detection.
- RPN module tells the Fast R-CNN where to look
- RPN -> takes an image as input and outputs a set of rectangular object proposals, each with an objectness score.
- Because the ultimate goal is to share computation with a Fast R-CNN object detection network we assume both nets
share a common set of convolutional layers.
- To generate proposals, we slide a small network over the convolutional feature map output by the last shared
convolutional layer.
- This small network takes an $n x n$ spatial window of the input convolutional feature map.
- Each slidding window is mapped to a lower-dimensional feature
- This feature is fed into two sibbling fully-connected layers - a box-regression layer and a box-classification layer(cls)
- Because the mini-network operates in a sliding-window fashion, the fully-connected layers are shared across all spatial locations
- This architecture is implemented with an $n \times n$ convolutional layer followed by two sibling 1x1 convolutional layers (for reg and cls)

### Anchors
- at each sliding-window location, we simultaneously predict multiple region proposals where the number of maximum possible proposals for each
location is denoted as $k$.
- The reg layer has 4k outputs encoding the coordinates of $k$ boxes and the cls layer outputs 2k scores that estimate probability of object
or not object for each proposal.
- The $k$ proposals are parameterized relative to $k$ reference boxes which are called anchors.
- An anchor is centered at the sliding window in question and is associated with a scale and aspect ratio

### Loss Function
- For training RPNs, we assign a binary class label (of being an object or not) to each anchor.
- We assign a positive label to two kinds of anchors :
    - The anchors with the highest IoU overlap with a ground-truth box
    - an anchor that has an IoU overlap higher than 0.7 with any ground-truth box
%% Skip

### Sharing features for RPN and Fast R-CNN
- Both RPN and Fast R-CNN trained independently will modify their convolutional
layers in different ways.
- Need to develop a technique that allows for sharing convolutional layers between the two networks
rather than learning two separate networks.
    - Alternating training. First train RPN, and use the proposals to train Fast R-CNN.
    The network tuned by Fast R-CNN is then used to initialize RPN, and this process is iterated.
    - Approximate joint training. RPN and Fast R-CNN merged into one network during training
    In each SGD iteration, the forward pass generates region proposals which are treated like fixed,
    pre-computed proposals when training a Fast R-CNN detector.
    - Non-approximate joint training. The bounding boxes predicted by RPN are functions of the input.
    The RoI pooling layer accepts the convolutional features and also the predicted bounding boxes

### 4-step alternating training
- Adopts a pragmatic 4-step training algorithm to learn shared features via alternating optimization
- Step1: train the RPN initialized with an ImageNet pre-trained model and fine-tuned end-to-end for
the region proposal task.
- Step2: train a separate detection network by Fast R-CNN using the proposals generated by step1
This net also initialized with ImageNet
- At this point the nets don't share convolutional layers.
- Step3: use the detector network to initialize RPN training, but fix the shared convolutional layers and only
fine-tune the layers unique to RPN.
- Now the two nets share convolutional layers.
- Finally keeping the shared convolutional layers fixed, fine-tune the unique layers of Fast R-CNN.
- So then both networks share the same convolutional layers and form a unified network

